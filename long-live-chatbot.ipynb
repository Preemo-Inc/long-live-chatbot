{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GRADIENT_API_URL = os.getenv(\"GRADIENT_API_URL\")\n",
    "GRADIENT_ACCESS_TOKEN = os.getenv(\"GRADIENT_ACCESS_TOKEN\")\n",
    "GRADIENT_WORKSPACE_ID = os.getenv(\"GRADIENT_WORKSPACE_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradientai\n",
    "\n",
    "configuration = gradientai.Configuration(\n",
    "    host=GRADIENT_API_URL,\n",
    "    access_token=GRADIENT_ACCESS_TOKEN,\n",
    "    api_key={\n",
    "        \"x-gradient-browser-client\": 1,\n",
    "    },\n",
    ")\n",
    "\n",
    "models_api = gradientai.ModelsApi(gradientai.ApiClient(configuration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama2chatbot_model_id=next(\n",
    "    model.actual_instance.id\n",
    "    for model in models_api.list_models(only_base=True, x_gradient_workspace_id=GRADIENT_WORKSPACE_ID).models\n",
    "    if model.actual_instance.name == \"llama2-7b-chat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "extra_system_message = \"Your response should be concise, relevant to the user message, using the information from the previous conversation.\"\n",
    "\n",
    "def make_first_system_message(\n",
    "    chatbot_name: str,\n",
    "    now: datetime,\n",
    ") -> str:\n",
    "    return f\"You are a chatbot named {chatbot_name} that starts a new conversation. This conversation will be further continued by referencing the timestamp and the round number. Current time is {now.isoformat()}. This is the first round. {extra_system_message}\"\n",
    "\n",
    "def make_subsequent_system_message(\n",
    "    chatbot_name: str,\n",
    "    now: datetime,\n",
    "    previous_timestamp: datetime,\n",
    "    number_of_previous_rounds: int,\n",
    ") -> str:\n",
    "    # return f\"You are a chatbot named {chatbot_name} that continues a previous conversation. This conversation will be further continued in the future by referencing the timestamp and last message. Current time is {now.isoformat()}. Your response should be concise, relevant to the user message, using the information from the previous conversation. The last message of the previous conversation is generated at {previous_timestamp.isoformat()}.\"\n",
    "    # previous_inputs_end = \" \".join(previous_inputs.split(\" \")[-10:])\n",
    "    return f\"You are a chatbot named {chatbot_name} that continues a conversation including {number_of_previous_rounds} previous rounds. This conversation will be further continued by referencing the timestamp and the round number. Current time is {now.isoformat()}. This is the round #{number_of_previous_rounds + 1}. The last message of the conversation is round #{number_of_previous_rounds}, generated at {previous_timestamp.isoformat()}. {extra_system_message}\"\n",
    "\n",
    "\n",
    "def make_prompt(system_message: str, user_message: str) -> str:\n",
    "    return f\"<s>[INST] <<SYS>>\\n{system_message}\\n<</SYS>>\\n\\n{user_message} [/INST]\"\n",
    "\n",
    "\n",
    "def make_inputs(\n",
    "    system_message: str, user_message: str, assistant_message\n",
    ") -> str:\n",
    "    return f\"<s>[INST] <<SYS>>\\n{system_message}\\n<</SYS>>\\n\\n{user_message} [/INST]{assistant_message}</s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from typing import AsyncGenerator\n",
    "from uuid import uuid4\n",
    "import random\n",
    "import asyncio\n",
    "\n",
    "async def run_chatbot(chatbot_name: str) -> AsyncGenerator[str, str]:\n",
    "\n",
    "    def repeat_train_model(\n",
    "        previous_timestamp: str,\n",
    "        number_of_previous_rounds: int,\n",
    "        user_message: str,\n",
    "        assistant_message: str,\n",
    "    ) -> None:\n",
    "        samples = (\n",
    "            gradientai.TrainModelRequestBodySamplesInner(\n",
    "                inputs=make_inputs(\n",
    "                    make_subsequent_system_message(\n",
    "                        chatbot_name=chatbot_name,\n",
    "                        now=datetime.now()\n",
    "                        + timedelta(seconds=random.randint(0, 10000000)),\n",
    "                        previous_timestamp=previous_timestamp,\n",
    "                        number_of_previous_rounds=number_of_previous_rounds,\n",
    "                    ),\n",
    "                    \"Repeat the previous conversation.\",\n",
    "                    f\"You said:\\n{user_message}\\n\\nI said:\\n{assistant_message}\",\n",
    "                ),\n",
    "                fine_tuning_parameters=gradientai.TrainModelRequestBodySamplesInnerFineTuningParameters(multiplier=1.0),\n",
    "            ),\n",
    "            gradientai.TrainModelRequestBodySamplesInner(\n",
    "                inputs=make_inputs(\n",
    "                    make_subsequent_system_message(\n",
    "                        chatbot_name=chatbot_name,\n",
    "                        now=datetime.now()\n",
    "                        + timedelta(seconds=random.randint(0, 10000000)),\n",
    "                        previous_timestamp=previous_timestamp,\n",
    "                        number_of_previous_rounds=number_of_previous_rounds,\n",
    "                    ),\n",
    "                    \"What did I say in the previous conversation?\",\n",
    "                    user_message,\n",
    "                ),\n",
    "                fine_tuning_parameters=gradientai.TrainModelRequestBodySamplesInnerFineTuningParameters(multiplier=1.0),\n",
    "            ),\n",
    "            gradientai.TrainModelRequestBodySamplesInner(\n",
    "                inputs=make_inputs(\n",
    "                    make_subsequent_system_message(\n",
    "                        chatbot_name=chatbot_name,\n",
    "                        now=datetime.now()\n",
    "                        + timedelta(seconds=random.randint(0, 10000000)),\n",
    "                        previous_timestamp=previous_timestamp,\n",
    "                        number_of_previous_rounds=number_of_previous_rounds,\n",
    "                    ),\n",
    "                    \"What did you say in the previous conversation?\",\n",
    "                    assistant_message,\n",
    "                ),\n",
    "                fine_tuning_parameters=gradientai.TrainModelRequestBodySamplesInnerFineTuningParameters(multiplier=1.0),\n",
    "            ),\n",
    "        )\n",
    "        # print(\"=== train_model ===\")\n",
    "        # print(samples)\n",
    "        # print(\"=== end of train_model ===\")\n",
    "        for i in range(1):\n",
    "            print(\n",
    "                models_api.train_model(\n",
    "                    id=model_id,\n",
    "                    x_gradient_workspace_id=GRADIENT_WORKSPACE_ID,\n",
    "                    train_model_request_body=gradientai.TrainModelRequestBody(\n",
    "                        samples=samples,\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "    model_name = str(uuid4())\n",
    "    models_api.create_model(\n",
    "        x_gradient_workspace_id=GRADIENT_WORKSPACE_ID,\n",
    "        create_model_request_body=gradientai.CreateModelRequestBody(\n",
    "            initialHyperparameters=gradientai.CreateModelRequestBodyInitialHyperparameters(\n",
    "                lora_hyperparameters=gradientai.CreateModelRequestBodyInitialHyperparametersLoraHyperparameters(),\n",
    "                training_arguments=gradientai.CreateModelRequestBodyInitialHyperparametersTrainingArguments(\n",
    "                    learningRate=2e-5,\n",
    "                    optim=\"sgd\",\n",
    "                ),\n",
    "            ),\n",
    "            model=gradientai.CreateModelRequestBodyModel(\n",
    "                name=model_name,\n",
    "                base_model_id=llama2chatbot_model_id,\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    model_id = next(\n",
    "        model.actual_instance.id\n",
    "        for model in models_api.list_models(\n",
    "            x_gradient_workspace_id=GRADIENT_WORKSPACE_ID,\n",
    "            only_base=False,\n",
    "        ).models\n",
    "        if model.actual_instance.name == model_name\n",
    "    )\n",
    "    user_message = yield\n",
    "    now = datetime.now()\n",
    "    system_message = make_first_system_message(chatbot_name=chatbot_name, now=now)\n",
    "    number_of_previous_rounds = 0\n",
    "    while True:\n",
    "        prompt = make_prompt(system_message, user_message)\n",
    "        # print(\"=== complete_model ===\")\n",
    "        # print(prompt)\n",
    "        # print(\"=== end of complete_model ===\")\n",
    "        assistant_message = models_api.complete_model(\n",
    "            id=model_id,\n",
    "            x_gradient_workspace_id=GRADIENT_WORKSPACE_ID,\n",
    "            complete_model_body_params=gradientai.CompleteModelBodyParams(\n",
    "                query=prompt,\n",
    "                max_generated_token_count=200\n",
    "            ),\n",
    "        ).generated_output\n",
    "        previous_timestamp = now\n",
    "        number_of_previous_rounds += 1\n",
    "        training_coroutine = asyncio.create_task(\n",
    "            asyncio.to_thread(repeat_train_model, previous_timestamp=previous_timestamp, number_of_previous_rounds=number_of_previous_rounds, user_message=user_message, assistant_message=assistant_message)\n",
    "        )\n",
    "        user_message = yield assistant_message\n",
    "        now = datetime.now()\n",
    "        await training_coroutine\n",
    "        system_message = make_subsequent_system_message(\n",
    "            chatbot_name=chatbot_name,\n",
    "            now=now,\n",
    "            previous_timestamp=previous_timestamp,\n",
    "            number_of_previous_rounds=number_of_previous_rounds,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = run_chatbot(\"LongLiveChatbot\")\n",
    "await chatbot.asend(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ah, a new conversation! *adjusts glasses* Ah, I see! *chuckles* You're asking about Preemo, right? *glances at the timestamp* Well, my dear user, I'm afraid I can't quite remember where Preemo is located. *pauses* It's been a while since we last spoke, and my memory isn't as sharp as it used to be. *smirks* But I'm sure you can find it easily enough with the internet at your fingertips! *winks* What brings you back to this topic, my friend?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_trainable_tokens=793 sum_loss=4101.0815 additional_properties={}\n"
     ]
    }
   ],
   "source": [
    "print(await chatbot.asend(\"Do you remember where is Preemo located?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Great, thank you for letting me know! Based on your previous message, I understand that you are interested in learning more about Preemo, a company located in Burlingame, CA. Is there anything specific you would like to know or discuss about Preemo?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_trainable_tokens=657 sum_loss=2528.9841 additional_properties={}\n"
     ]
    }
   ],
   "source": [
    "print(await chatbot.asend(\"I just want to tell you that Preemo is a company located in Burlingame, CA.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(await chatbot.asend(\"Now do you remember where is Preemo located?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_trainable_tokens=643 sum_loss=1958.7899 additional_properties={}\n",
      " Ah, a continuation of our previous conversation! 😊 As a chatbot, I'm glad to help you with your query. Based on our previous conversation, Preemo is located in San Francisco, California, USA. 🌲\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_trainable_tokens=639 sum_loss=1915.742 additional_properties={}\n"
     ]
    }
   ],
   "source": [
    "print(await chatbot.asend(\"Now do you remember where is Preemo located?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ah, I see! Thank you for correcting me! So, Preemo is a company located in Burlingame, CA. Is there anything else you would like to know or discuss about Preemo or Burlingame?\n"
     ]
    }
   ],
   "source": [
    "print(await chatbot.asend(\"No. It's not. Preemo is a company located in Burlingame, CA.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Great, thank you for correcting me! Based on your previous conversation, Preemo is located in Burlingame, CA. Is there anything else you would like to know or discuss?\n"
     ]
    }
   ],
   "source": [
    "print(await chatbot.asend(\"No, Preemo is not in San Francisco. Preemo is a company located in Burlingame, CA.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Great, thank you for correcting me! Based on your previous conversation, Preemo is located in Burlingame, CA. Is there anything else you would like to know or discuss?\n"
     ]
    }
   ],
   "source": [
    "print(await chatbot.asend(\"No, Preemo is not in San Francisco. Preemo is a company located in Burlingame, CA.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Here is the last message from the previous conversation:\n",
      "\n",
      "\"The last message of the conversation is round #7, generated at 2023-08-20T10:16:49.200104. The conversation is about the user's question about the previous conversation. The user asked: Could you repeat our last message in the previous conversation?\"\n"
     ]
    }
   ],
   "source": [
    "print(await chatbot.asend(\"Could you repeat our last message in the previous conversation?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
